{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji \n",
    "import codecs\n",
    "\n",
    "df = pd.read_csv(\"proc_tweets.csv\",low_memory=False, nrows=100000, usecols=[\"TIME POSTED\",\"TWITTER'S TIME POSTED\",\"RETWEET\"])\n",
    "\n",
    "df[\"emoji\"] = df[\"RETWEET\"].apply(lambda x: [i for i in str(x).split() if i in emoji.UNICODE_EMOJI])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def senti_data(filename_pos, filename_neg):\n",
    "    '''\n",
    "    Converts a list of positive and negative words into a lists.\n",
    "    Output: pos: List of all positive words\n",
    "            neg: List of all negative words\n",
    "    '''\n",
    "    positive_vocab = ''\n",
    "    negative_vocab = ''\n",
    "\n",
    "    with open(filename_pos, 'r') as f:\n",
    "        for line in f:\n",
    "            positive_vocab += line.strip() + ' '\n",
    "\n",
    "    with open(filename_neg, 'r') as f:\n",
    "        for line in f:\n",
    "            negative_vocab += line.strip() + ' '\n",
    "    pos = []\n",
    "    neg = []\n",
    "    pos.append(positive_vocab)\n",
    "    neg.append(negative_vocab)\n",
    "    return pos, neg\n",
    "\n",
    "\n",
    "#Creating Vectorizer and transforming data\n",
    "cv = TfidfVectorizer(ngram_range=(1,3), stop_words='english', strip_accents='unicode')\n",
    "tf = cv.fit_transform(df['RETWEET'].apply(lambda x: np.str_(x)))\n",
    "\n",
    "#Getting positive and negative words list\n",
    "pos, neg = senti_data('data/pos.txt','data/neg.txt')\n",
    "\n",
    "#Converting the words list to vectors\n",
    "pos_vec = cv.transform(pos)\n",
    "neg_vec = cv.transform(neg)\n",
    "\n",
    "#Calculating similarity between each tweet and the positive vector\n",
    "pos_score = np.asanyarray(cosine_similarity(tf.toarray(),pos_vec))\n",
    "neg_score = np.asanyarray(cosine_similarity(tf.toarray(),neg_vec))\n",
    "\n",
    "#Calculating net score, assuming that each tweet would have a positive and negative score associated with it. And the net difference would give me the net orientation of the tweet.\n",
    "score = pos_score - neg_score\n",
    "\n",
    "# #Getting the top 20 tweets with a positive sentiment\n",
    "# top_tweets = np.argsort(score.ravel())[-20:][::-1]\n",
    "# for index, top_tweet in enumerate(top_tweets):\n",
    "#     print(df.RETWEET[top_tweet],score.ravel()[top_tweet] )\n",
    "\n",
    "df[\"score\"] = score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_emoticons = df[\"emoji\"].explode().unique()[1:40]\n",
    "\n",
    "for emoticon in tracked_emoticons:\n",
    "    df[emoticon]=0\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    for emoji in row[\"emoji\"]:\n",
    "        if emoji in tracked_emoticons:\n",
    "            df.loc[index, emoji] = row[\"score\"]\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[\"TWITTER'S TIME POSTED\",\n",
    "#        'ğŸ˜­', 'â¤ï¸', 'ğŸ˜…', 'ğŸ’ª', 'ğŸ˜', 'ğŸ‡ºğŸ‡¦', 'ğŸ‘', 'ğŸ™„', 'ğŸ¥µ', 'ğŸ”¥', 'ğŸŒ¶', 'ğŸ˜‚', 'ğŸ‘', 'ğŸ™',\n",
    "#        'ğŸ˜˜', 'ğŸ˜', 'ğŸ¤£', 'ğŸ˜‰', 'ğŸ”´', 'ğŸ¤”', 'ğŸ’•', 'â˜ºï¸', 'Â©', 'ğŸ‰', 'ğŸ˜Š', 'ğŸ¤©', 'ğŸ’«', 'ğŸ˜»',\n",
    "#        'ğŸ’™', 'ğŸ‘', 'ğŸ‡µğŸ‡¹', 'ğŸ’–', 'â™¥ï¸', 'ğŸ™ğŸ½', 'ğŸ’¯', 'ğŸ˜†', 'ğŸ‘€', 'ğŸ˜œ', 'ğŸ˜']].sort_values(by=\"TWITTER'S TIME POSTED\").cumsum().plot(figsize=(50,20), fontproperties=\"prop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[\"TWITTER'S TIME POSTED\"] = pd.to_datetime(df[\"TWITTER'S TIME POSTED\"], format='%Y-%m-%d %H:%M:%S')\n",
    "df.set_index([\"TWITTER'S TIME POSTED\"],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ax = df[[\n",
    "       'ğŸ˜­', 'â¤ï¸', 'ğŸ˜…', 'ğŸ˜', 'ğŸ˜‚']].cumsum().plot(figsize=(13,5),ylabel=\"Sentiment\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
